{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import matplotlib.pyplot as plt\n", "import torch, torch.nn as nn\n", "from torch.utils.data import TensorDataset, DataLoader\n", "from torch.optim.lr_scheduler import StepLR\n", "# define input size, hidden layer size, output size\n", "D_i, D_k, D_o = 10, 40, 5\n", "# create model with two hidden layers\n", "model = nn.Sequential(\n", " nn.Linear(D_i, D_k),\n", " nn.ReLU(),\n", " nn.Linear(D_k, D_k),\n", " nn.ReLU(),\n", " nn.Linear(D_k, D_o))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["He initialization of weights"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def weights_init(layer_in):\n", " if isinstance(layer_in, nn.Linear):\n", "  nn.init.kaiming_normal_(layer_in.weight)\n", "  layer_in.bias.data.fill_(0.0)\n", "model.apply(weights_init)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["choose least squares loss function"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["criterion = nn.MSELoss()\n", "# construct SGD optimizer and initialize learning rate and momentum\n", "optimizer = torch.optim.SGD(model.parameters(), lr = 0.1, momentum=0.9)\n", "# object that decreases learning rate by half every 10 epochs\n", "scheduler = StepLR(optimizer, step_size=10, gamma=0.5)\n", "# create 100 random data points and store in data loader class\n", "x = torch.randn(100, D_i)\n", "y = torch.randn(100, D_o)\n", "data_loader = DataLoader(TensorDataset(x,y), batch_size=10, shuffle=True)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["for plotting data"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["fig, ax = plt.subplots()\n", "epochs = []\n", "epoch_losses = []\n", "# loop over the dataset 100 times\n", "for epoch in range(100):\n", " epoch_loss = 0.0\n", " # loop over batches\n", " for i, data in enumerate(data_loader):\n", "  # retrieve inputs and labels for this batch\n", "  x_batch, y_batch = data\n", "  # zero the parameter gradients\n", "  optimizer.zero_grad()\n", "  # forward pass\n", "  pred = model(x_batch)\n", "  loss = criterion(pred, y_batch)\n", "  # backward pass\n", "  loss.backward()\n", "  # SGD update\n", "  optimizer.step()\n", "  # update statistics\n", "  epoch_loss += loss.item()\n", " # print error\n", " print(f'Epoch {epoch:5d}, loss {epoch_loss:.3f}')\n", " #send to plot\n", " epochs.append(epoch)\n", " epoch_losses.append(epoch_loss)\n", " # tell scheduler to consider updating learning rate\n", " scheduler.step()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["ax.plot(epochs, epoch_losses)\n", "ax.set_xlabel('Epoch'); ax.set_ylabel('Loss')\n", "ax.set_xlim([0,100]);ax.set_ylim([0,20])\n", "ax.set_aspect(1.0)\n", "plt.show()"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}